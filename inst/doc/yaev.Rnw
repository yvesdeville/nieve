\documentclass[11pt]{article}

%% ===========================================================================
%% Copyright Yves Deville <deville.yves@alpestat.com> 2022
%% ===========================================================================

\usepackage{amsmath,amssymb,amsthm}
\usepackage[english]{babel}
\usepackage[amsmath]{maxiplot}
\usepackage{fullpage}
\usepackage{lscape}
\usepackage{hyperref}
\usepackage{tikz}
\definecolor{MonVert}{rgb}{0.398,0.801,0.000} 
\definecolor{MonVertF}{rgb}{0.13,0.54,0.13}
\definecolor{MonRouge}{rgb}{0.600,0.060,0.360} 
\definecolor{MonBleu}{rgb}{0.000,0.602,0.801} 
\definecolor{SteelBlue2}{rgb}{0.359375,0.671875,0.9296875}
\definecolor{orange}{rgb}{1.0,0.6470,0.0}
\definecolor{SteelBlue4}{rgb}{0.212, 0.392, 0.545}
\definecolor{MonJaune}{rgb}{0.996,0.996,0.875}
\definecolor{orange1}{rgb}{0.996,0.645,0}
\definecolor{PaleVioletRed}{rgb}{0.855,0.438,0.574}
\newcommand{\m}{\mathbf}   
\newcommand{\bs}{\boldsymbol}
\newcommand{\pkg}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}

\title{\bf \Large The \textbf{yaev} package: Yet Another Extreme Value package?}

\author{Yves Deville \href{mailto:deville.yves@alpestat.com}%%
  {deville.yves@alpestat.com} }

\begin{document}
\maketitle{}
\tableofcontents{}

\section{Probability functions of Extreme-Value distributions}
  
The probability functions for the GPD and GEV distributions depend
smoothly on the parameters: they are infinitely differentiable
functions of the parameters. However these functions are not analytic
functions of the parameters and a singularity exists for all the
functions when the shape parameter say $\xi$ is zero.  In practice,
the functions are given with different formulas depending on whether
$\xi$ is zero or not; the formulas for $\xi = 0$ relate to the
exponential and Gumbel distributions and correspond to the limit for
$\xi \to 0$ of the functions given by the formulas for $\xi \neq 0$.
As an example consider the quantile function of the Generalized Pareto
distribution with shape $\xi$ and unit scale
\begin{equation}
\label{eq:Quant}
q(p) = \begin{cases}
  [(1 - p)^{-\xi} - 1] / \xi & \xi \neq 0 \\
  -\log(1 - p) & \xi = 0,
\end{cases} \qquad 0 < p < 1.
\end{equation}
It can be shown that for $\xi \approx 0$ whatever be $p$
$$
q \approx - \log(1-p), \qquad
\frac{\partial q}{\partial \xi} \approx \frac{1}{2}\, \log^2(1-p), \qquad
\frac{\partial^2 q}{\partial \xi^2} \approx -\frac{1}{3}\, \log^2(1-p).
$$
It is quite easy to obtain expressions for the the derivatives
w.r.t. $\xi$ using the definition (\ref{eq:Quant}). We can even rely
on the symbolic derivation method \verb@D@ available in R which, as
opposed to me and many other humans, never makes any mistake when
differentiating.

<<deriv, size= "footnotesize">>=
qEx <- function(p, xi) ((1 - p)^(-xi) - 1) / xi
dqEx <- D(expression(((1 - p)^(-xi) - 1) / xi), name = "xi")
d2qEx <- D(dqEx, name = "xi")
p <- 0.99; q <- 1 - p
for (xi in c(1e-4, 1e-6, 1e-8)) {
    r <- rbind("ord 0" = c("lim" = -log(q), "der" = qEx(p = p, xi = xi)),
               "ord 1" = c("lim" = log(q)^2 / 2, "der" = eval(dqEx, list(p = p, xi = xi))),
               "ord 2" = c("lim" = -log(q)^3 / 3, "der" = eval(d2qEx, list(x = p, xi = xi))))
    cat("xi = ", xi, "\n")
    print(r)
}
@ 

\noindent
We see that the formula for the function works fine. However, the
formula for the 2-nd order derivative can be completely wrong when
$\xi$ is about $\text{1e-6}$ and the formula for the 1-st order
derivative wan also be wrong whe $\xi$ is about $\text{1e-8}$. The
reason is that the formulas for the derivatives involve difference
and/or fractions or small quantities since $\xi$ or $\xi^2$ comes at
the denominator. As a general rule the derivatives with higher order
are more difficult to evaluate numerically, since they involve more
complex expressions.  Note that using $\xi \leqslant \text{1e-6}$ is
quite common in EVA because the values of $\xi$ used in practice are
often quite small, and moreover a very small value of $\xi$ is often
used in the initialisation of the Maximum-Likelihood (ML)
optimization.

Although not yet widespread, the use of the exact formulas for the
derivatives w.r.t. the parameters can be of great help in the
optimization tasks required in EVA. These tasks of course involve the
ML estimation but also profile-likelihood inference for models with
covariates. Differential equations methods can be also used to derive
confidence intervals. Note that using the formulas for the derivatives
is \textit{symbolic} differentiation, which differs from
\textit{automatic} differentiation as increasingly available.

Our strategy consists in fixing a small $\epsilon >0$ and use the
formulas only when $|\xi| > \epsilon$. When
$|\xi| \leqslant \epsilon$, we use a few terms from the Taylor series
at $\xi =0$. In order to maintain the consistency between the
derivatives, it seems good to use the same $\epsilon$ for all the
derivatives and use consistent Taylor approximations. Since the $2$-nd
order derivatives can be required, we must take a value for $\epsilon$
which is not too small: $\text{1e-4}$ or $\text{1e-5}$, not much
smaller. This method is used in some codes of the \textbf{revdbayes} package
by Paul Northrop.

\section{Deriving the formulas}

The reports provided with \textbf{yaev} give the exact expressions for
the first-order and the second-order derivatives of the probability
functions w.r.t. the parameters and also provides workable
approximations for the case $\xi \approx 0$. We used the
\href{https://maxima.sourceforge.io/}{Maxima Computer Algebra System}
along with the
\href{https://maxima.sourceforge.io/contrib/maxiplot/maxiplot.sty}{maxiplot}
package for \LaTeX{}.

\begin{itemize}
\item The {\color{MonVertF} \bf raw expressions given by Maxima are
    reported in green}. The expressions can be regarded as exact, not
  being influenced by manual computations. However these formulas are
  usually difficult to use in a compiled code and require some manual
  transformation for this aim.

\item The {\color{red} \bf simplified expressions are reported in
    red}.  These expressions are derived by us from the raw
  expressions; they are influenced by manual computations hence could
  in principle contain errors, although they have been carefully
  checked. These formulas are used to write the compiled code.  They
  often use auxiliary variables that are shared across several
  formulas.
  
\end{itemize}

\section{Testing}

The \textbf{yaev} package comes with a series of tests in the format
of the \textbf{testthat} package. The \textbf{numDeriv} package is
used to compute the derivatives up to order 2 by numeric
differentiation. These derivatives can be compared to those provided
by the formulas.

A quite difficult task when checking derivatives is to give a
threshold used to decide if the difference between the numeric
derivative and the symbolic derivative, say the ``error'', is
acceptable or not. When a derivative is small, the relative error may
be large.  On the other side, when a derivative is large in absolute
value, the absolute error may also be quite large.  Mind that the
derivatives can be quite large in practice and also that a gradient
vector or a Hessian matrix often contain values that are not of the
same order of magnitude.

We check that \textit{the absolute error or the relative error is
  small}. The idea is that none of these two things can come by
chance, and if one holds, the formula used must be good even if the
other criterion suggests an opposed conclusion. The test is made
\textit{elementwise} meaning that the relative error is computed for
each element of a gradient vector or Hessian matrix ignoring the other
elements.

\section{POT to NHPP parameterizations}

XXX To be completed

% Peak Over Threshold (POT) models are very popular in EVA. A threshold
% $u$. 

% \begin{itemize}
% \item Poisson-GP
% \item PP (for Point Process) or NHPP (for Non-Homogeneous Poisson
%   Proces)
% \end{itemize}

% The main difference is that 

% The \textbf{yaev} package provides the two transformations.

\section{EV distributions from other R packages}

The EV distributions are implemented in many R packages. A variety of
strategies regarding the problem $\xi = 0$ can be found. We now
describe these strategies and provide a code for each of them as used
in Table~\ref{TabXi}, columns $\xi = 0$. Each strategy is briefly
discussed.

\begin{enumerate}

\item  \fbox{NT} Use only the formula for $\xi \neq 0$ i.e., {``do nothing''}.
  In practice, an optimisation or sampling algorithm will never come
  to the case $\xi = 0$ exactly!  If the distribution is estimated
  with no possible constraint or initialisation with $\xi = 0$, there
  will be no problem.
  
\item \fbox{$0.0$} Test the exact equality $\xi = 0$, and if this is true,
  \textit{switch to the exponential/Gumbel formula}.  This helps only
  when the user gives \code{xi = 0.0}. There will be some numerical
  problems when $\xi$ is very small, say $\xi = \text{1e-8}$ or
  less. These problems are not so crucial for the usual probability
  functions: we get some wiggling when plotting the curves and
  zooming. Mind however that the random generation \code{rgev} or
  \code{rgpd} will produce silly results with very small $\xi$ if they
  use \code{qgev} or \code{qgpd}.

\item  \fbox{$\epsilon$/S}  Test the equality $ |\xi| \leqslant \epsilon$ where
  $\epsilon >0$ is very small, and if this is true, \textit{switch
    to the exponential/Gumbel formula}. So this produces a (very
  small) discontinuity.  E.g., \pkg{Renext} uses
  $\epsilon \approx \text{2e-14}$.
  
  
\item \fbox{$\epsilon$/AI} Test the equality
  $ |\xi| \leqslant \epsilon$ where $\epsilon >0$ is very small, and
  if this is true, use a dedicated \textit{approximation or
    interpolation}.  Several methods can be used including Taylor
  approximations. The discontinuity should then be undetectable.  Mind
  the probability functions although not being \textit{analytic}
  functions, are infinitely differentiable $C^\infty$ w.r.t. the
  parameters!
  
\end{enumerate}


\begin{table}
    \centering \small
    \begin{tabular}{| l || c | c | c | c | c || c | c | c | c | c |}
      \hline
      \multicolumn{1}{|c||}{\raisebox{-0.3em}{Package}}
      & \multicolumn{5}{c||}{GEV}
      & \multicolumn{5}{c|}{GPD}\\ \cline{2-6} \cline{7-11}
      \multicolumn{1}{|c||}{}
      & \multicolumn{1}{c|}{Lang.}
      & \multicolumn{1}{c|}{Vec. $\bs{\theta}$}
      & \multicolumn{1}{c|}{Grad.}
      & \multicolumn{1}{c|}{Hess.}
      & \multicolumn{1}{c||}{$\xi=0$}
      & \multicolumn{1}{c|}{Lang.}
      & \multicolumn{1}{c|}{Vec. $\bs{\theta}$}
      & \multicolumn{1}{c|}{Grad.}
      & \multicolumn{1}{c|}{Hess.}
      & \multicolumn{1}{c|}{$\xi=0$} \\ \hline\hline
      \textbf{evir}
      & R & no & no & no & NT & R & no & no & no & NT\\ \hline
      \textbf{evd}
      & R & no & no & no & 0.0 & R & no & no & no & 0.0\\ \hline
      \textbf{ismev}
      & R$^\star$ & no & no & no & NT & R$^\star$ & no & no & no & NT\\ \hline
      \textbf{Renext}
      &  &  &  &  &  & R & no & yes & yes & $\epsilon$/S \\ \hline
      \textbf{POT}
      &  &  &  &  &  & R$^\star$ & yes & no & no & 0.0 \\ \hline
      \textbf{SpatialExtremes}
      & R  & yes & no & no & $0.0$ & R & yes & no & no & $0.0$ \\ \hline   
      \textbf{revdbayes}
      & R  & yes & no & no & $\epsilon$/AI & R & yes & no & no & $\epsilon$/AI \\ \hline
      \textbf{mev}
      & R  & yes & yes$^\star$ & yes$^\star$& NT & R & yes & yes$^\star$
      & yes$^\star$ & NT \\ \hline
      {\color{red}\textbf{yaev}}
      & C & yes & yes & yes & $\epsilon$/AI   
      & C & yes & yes & yes & $\epsilon$/AI \\ \hline
    \end{tabular}
    \caption{\small \sf Features of some CRAN packages \label{TabXi}
      \textit{Lang.}: the implementation language, \textit{Vec.}
      $\bs{\theta}$: vectorized w.r.t. the parameters. The columns
      \textit{Grad.} and \textit{Hess.}  indicate if the gradient and
      Hessian are provided, and the colums $\epsilon = 0$ indicate the
      strategy used to cope with a zero or small shape, as described
      in the text. A star means that the functions are not exported.}
  \end{table}


\section*{Acknowledgments}

We are grateful to the authors and contributors of \textbf{Maxima} and
to the authors of the \textbf{maxiplot} \LaTeX{} package (J.M. Planas
and José Manuel Mira univ. de Murcia, Spain) which helped much for the
tedious computations required by the package.

\end{document}
