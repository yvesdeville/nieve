\documentclass[11pt]{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage[english]{babel}
\usepackage[amsmath]{maxiplot}
\usepackage{fullpage}
\usepackage{lscape}
\usepackage{hyperref}
\usepackage{tikz}
\definecolor{MonVert}{rgb}{0.398,0.801,0.000} 
\definecolor{MonVertF}{rgb}{0.13,0.54,0.13}
\definecolor{MonRouge}{rgb}{0.600,0.060,0.360} 
\definecolor{MonBleu}{rgb}{0.000,0.602,0.801} 
\definecolor{SteelBlue2}{rgb}{0.359375,0.671875,0.9296875}
\definecolor{orange}{rgb}{1.0,0.6470,0.0}
\definecolor{SteelBlue4}{rgb}{0.212, 0.392, 0.545}
\definecolor{MonJaune}{rgb}{0.996,0.996,0.875}
\definecolor{orange1}{rgb}{0.996,0.645,0}
\definecolor{PaleVioletRed}{rgb}{0.855,0.438,0.574}

\title{The \textbf{yaev} package: Yet Another Extreme Value package?}

\author{Yves Deville \href{mailto:deville.yves@alpestat.com}%%
  {deville.yves@alpestat.com} }

\begin{document}
\maketitle{}
\tableofcontents{}

\section{Probability functions of Extreme-Value distributions}
  
The probability functions for the GPD and GEV distributions depend
smoothly on the parameters: they are infinitely differentiable
functions of the parameters. However these functions are not analytic
functions of the parameters and a singularity exists for all the
functions when the shape parameter say $\xi$ is zero.  In practice,
the functions are given with different formulas depending on whether
$\xi$ is zero or not; the formulas for $\xi = 0$ relate to the
exponential and Gumbel distributions and correspond to the limit for
$\xi \to 0$ of the functions given by the formulas for $\xi \neq 0$.
As an example consider the quantile function of the Generalized Pareto
distribution with shape $\xi$ and unit scale
\begin{equation}
\label{eq:Quant}
q(p) = \begin{cases}
  [(1 - p)^{-\xi} - 1] / \xi & \xi \neq 0 \\
  -\log(1 - p) & \xi = 0,
\end{cases} \qquad 0 < p < 1.
\end{equation}
It can be shown that for $\xi \approx 0$ whatever be $p$
$$
q \approx - \log(1-p), \qquad
\frac{\partial q}{\partial \xi} \approx \frac{1}{2}\, \log^2(1-p), \qquad
\frac{\partial^2 q}{\partial \xi^2} \approx -\frac{1}{3}\, \log^2(1-p).
$$
It is quite easy to obtain expressions for the the derivatives
w.r.t. $\xi$ using the definition (\ref{eq:Quant}). We can even rely
on the symbolic derivation method \verb@D@ available in R which, as
opposed to me and many other humans, never makes any mistake when
differentiating.

<<deriv, size= "footnotesize">>=
qEx <- function(p, xi) ((1 - p)^(-xi) - 1) / xi
dqEx <- D(expression(((1 - p)^(-xi) - 1) / xi), name = "xi")
d2qEx <- D(dqEx, name = "xi")
p <- 0.99; q <- 1 - p
for (xi in c(1e-4, 1e-6, 1e-8)) {
    r <- rbind("ord 0" = c("lim" = -log(q), "der" = qEx(p = p, xi = xi)),
               "ord 1" = c("lim" = log(q)^2 / 2, "der" = eval(dqEx, list(p = p, xi = xi))),
               "ord 2" = c("lim" = -log(q)^3 / 3, "der" = eval(d2qEx, list(x = p, xi = xi))))
    cat("xi = ", xi, "\n")
    print(r)
}
@ 

\noindent
We see that the formula for the function works fine. However, the
formula for the 2-nd order derivative can be completely wrong when
$\xi$ is about $\text{1e-6}$ an the formula for the 1-st order
derivative wan also be wrong whe $\xi$ is about $\text{1e-8}$. The
reason is that the formulas for the derivatives involve difference
and/or fractions or small quantities since $\xi$ or $\xi^2$ comes at
the denominator. As a general rule the derivatives with higher order
are more difficult to evaluate, since they involve more complex
expressions.  Note that using $\xi \approx \text{1e-6}$ is quite
common in EVA because the values of $\xi$ used in practice are often
quite small, and moreover a very small value of $\xi$ is often used in
the initialisation of the Maximum-Likelihood (ML) optimization.

Although not yet widespread, the use of the exact formulas for the
derivatives w.r.t. the parameters can be of great help in the
optimization tasks required in EVA. These tasks of course involve the
ML estimation but also profile-likelihood inference for models with
covariates. Differential equations methods can be also used to derive
confidence intervals. Note that using the formulas for the derivatives
is \textit{symbolic} differentiation, which differs from
\textit{automatic} differentiation as increasingly available.

Our strategy consists in fixing a small $\epsilon >0$ and use the
formulas only when $|\xi| > \epsilon$. When
$|\xi| \leqslant \epsilon$, we use a few terms from the Taylor series
at $\xi =0$. In order to maintain the consistency between the
derivatives, it seems good to use the same $\epsilon$ for all the
derivatives and use consistent Taylor approximations. Since the $2$-nd
order derivatives can be required, we must take a value for
$\epsilon$ which is not too small: $\text{1e-4}$ or $\text{1e-5}$, not
much smaller.

\section{Deriving the formulas}

The reports provided with \textbf{yaev} give the exact expressions for
the first-order and the second-order derivatives of the probability
functions w.r.t. the parameters and also provides workable
approximations for the case $\xi \approx 0$. We used the
\href{https://maxima.sourceforge.io/}{Maxima Computer Algebra System}
along with the
\href{https://maxima.sourceforge.io/contrib/maxiplot/maxiplot.sty}{maxiplot}
package for \LaTeX{}.

\begin{itemize}
\item The {\color{MonVertF} \bf raw expressions given by Maxima are reported
    in green}. The expressions can be regarded
  as exact, not being influenced by manual computations. However
  these formulas are usually difficult to use in a compiled code.

\item The {\color{red} \bf simplified expressions are reported in
    red}.  These expressions are derived by us from the raw
  expressions; they are influenced by manual computations hence could
  in principle contain errors, although they have been carefully
  checked. These formulas are used to write the compiled code.
  
\end{itemize}

\section{Testing}

The \textbf{yaev} package comes with a series of tests in the format
of the \textbf{testthat} package. The \textbf{numDeriv} package is
used to compute the derivatives up to order 2 by numeric
differentiation. These derivatives can be compared to those provided
by the formulas.

A quite difficult task when checking derivatives is to give a
threshold used to decide if the difference between the numeric
derivative and the symbolic derivative, say the ``error'', is
acceptable or not. When a derivative is small, the relative error may
be large.  On the other side, when a derivative is large in absolute
value, the absolute error may also be quite large.  Mind that the
derivatives can be quite large in practice and also that a gradient
vector or a Hessian matrix often contain values that are not of the
same order of magnitude.

We check that \textit{the absolute error or the relative error is
  small}. The idea is that none of these two things can come by
chance, and if one holds, the formula used must be good. The test is
made \textit{elementwise} meaning that the relative error is computed
for each element of a gradient vector or Hessian matrix ignoring the
other elements.

\section{POT to NHPP parameterizations}

XXX To be completed

% Peak Over Threshold (POT) models are very popular in EVA. A threshold
% $u$. 

% \begin{itemize}
% \item Poisson-GP
% \item PP (for Point Process) or NHPP (for Non-Homogeneous Poisson
%   Proces)
% \end{itemize}

% The main difference is that 

% The \textbf{yaev} package provides the two transformations.

\section{EV distributions from other R packages}

XXX To be completed


\end{document}
